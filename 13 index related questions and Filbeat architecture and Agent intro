What is the index?
What is the shard?
What is the replica and what is primaryh shard?
What is the replica and what is the primary shard?
What is the dataview?
What is the documents?
what is the default shard size in elk

Index is a collection of shards. 
We can related it to the database scheme, when we create a database, we create a schema (source of data)
so under scheme multiple tables come, in the elk multiple tables doesnt come shards come in form of table. 

When we read from the schema, we need to create a pattern which is a dataview and this dataview matches the pattern with the index name and provide the document to the interface and we will be able to visualize the documents which is data.

Primary is where data is located and searchable and shard replica is a backup of the primary shard.
shard size, we can create upto 40gb 


❓ What is a shard?
👉 Is a shard a smaller piece of an index?
Exactly! A shard is like a slice of the index. If your data is too big, ELK breaks it into shards to spread across servers and make searching faster.

❓ What is a primary shard?
👉 Is the primary shard the original copy of the data?
Yes! The primary shard holds the main data. Every piece of data goes into the primary shard first.

❓ What is a replica shard?
👉 Is the replica shard a backup of the primary shard?
Yes! A replica shard is just a copy of a primary shard. It's used for backup and faster searching in case one node fails.

❓ What is a data view in Kibana?
👉 Is a data view how I look at my index in Kibana?
Yes! A data view (previously called index pattern) is how you connect Kibana to one or more indexes so you can search, filter, and visualize your data.

❓ What is a document in ELK?
👉 Is a document like one row of data?
Exactly! A document is one single entry or record. Like one log line, one user activity, or one error report.

❓ What is the default shard size in elk?
👉 Is there a fixed size for each shard by default?
Not exactly — there’s no hard size limit, but Elasticsearch recommends keeping each shard under 50GB for best performance.

✅ Best practice: Try to keep shard size around 20–40 GB, depending on your use case.
So in summary:

There's no strict limit, but...
Too small = too many shards = waste of memory
Too big = slow performance or errors
🧠 Think of shards like pizza slices — not too many tiny slices, not one giant slice!
Let me know if you want to see how to check shard sizes with a command!

------------------------
INDEX TEMPALTE :
------------------------
- Index template is a predefined format, in which data will be molded as per settings defined in the index template
- if we dont define the index template, then by default index's will be using ecs (elastic common schema)

how the index template matches? we define the index pattern in the settings



------------------------
FILEBEAT ARCHITECTURE:
------------------------
We will create the file beat architecture now:

kibana
logstash
filebeat
webapplication (structured and unstructured data) 
  structured: /opt/test/logs/my-structured.logs
  unstructured: /opt/test/logs/my-unstructured.logs


structure ex: {"name": "shivam"}
unstructured ex: name shivam age 30

anything (data) readable by the machine is structured 
anything (data) not readable by the machine is ustructured 


in elasticsearch there are fleet of agents:

there multiple agents
beats:
apm
etl - logstash

for different purpose we have different beats:
Beats
Filebeat. Lightweight shipper for logs and other data, Metricbeat. Lightweight shipper for metric data.
Packetbeat. Lightweight shipper for network data.
Winlogbeat. Lightweight shipper for Windows event logs.
Auditbeat. Lightweight shipper for audit data.
Heartbeat. Lightweight shipper for uptime monitoring.

we can put multiple processors in the filebeat
INPUT 
  -logs
  -/opts/test/logs/*.log  (inode numbers is the way filebeats rememeber from where the file is being read)
PROCESSORS  
  customization
  adding some tags
    service_name = web
    server_env = prod
  dropping some unwanted data
OUTPUT
  LOGSTASH
  ELK

Logs : information about process or error or debug info of any server or application
Metrics: metric is data through which we can measure system resrouce utilization performance validation
  Cpu, memory, resource, network, IO, storage, and etc
windlogbeat: windows to collect windows events data 
Heartbeat: api, server is up or not is there any lattency or not, url monitoring, etc







