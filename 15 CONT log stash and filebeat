

filebeat.yml 
input >> /file
output >> logstash:5055

Logstash/conf.d/<file.conf>
input >> beats 5044
filter >>
output >> ELK

Agents:
in ELK stack these are all the agents:
Beats (file, metric, heart)
logstash
other agents

Ui: 
Kibana

clear
Database: 
ELK

### command to run the logstash
root@elk:/etc/logstash/conf.d# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/filebeat.conf

### on filebeat server node 6 run filebeat
root@elk:/var/log# systemctl start filebeat
root@elk:/var/log# vim my_data.log
testing
wq!

### OUTPUT ON NODE 5 logstash 
{
         "agent" => {
                "name" => "elk",
                "type" => "filebeat",
        "ephemeral_id" => "0b2f8e70-db95-437d-a46e-fc9b24b5846b",
                  "id" => "d7a4dfcb-de4e-4bbf-b0a1-060c65dab621",
             "version" => "8.18.1"
    },
         "event" => {
        "original" => "2025-08-03 01:37:41 status installed telnet:all 0.17+2.5-3ubuntu4"
    },
          "host" => {
                  "mac" => [
            [0] "00-1C-42-6D-E0-89"
        ],
        "containerized" => false,
             "hostname" => "elk",
                   "os" => {
              "kernel" => "6.8.0-64-generic",
                "name" => "Ubuntu",
            "codename" => "noble",
                "type" => "linux",
            "platform" => "ubuntu",
              "family" => "debian",
             "version" => "24.04.2 LTS (Noble Numbat)"
        },
                   "ip" => [
            [0] "10.211.55.32",
            [1] "fdb2:2c26:f4e4:0:21c:42ff:fe6d:e089",
            [2] "fe80::21c:42ff:fe6d:e089"
        ],
                 "name" => "elk",
         "architecture" => "aarch64",
                   "id" => "53d351d845dc4ea09111e51cc53b4b62"
    },
          "tags" => [
        [0] "beats_input_codec_plain_applied"
    ],
           "ecs" => {
        "version" => "8.0.0"
    },
           "log" => {
        "offset" => 578296,
          "file" => {
                "inode" => "133150",
                 "path" => "/var/log/dpkg.log",
            "device_id" => "64512"
        }
    },
       "message" => "2025-08-03 01:37:41 status installed telnet:all 0.17+2.5-3ubuntu4",
      "@version" => "1",
    "@timestamp" => 2025-08-03T01:37:41.899Z,
         "input" => {
        "type" => "filestream"
    }
}
{
         "agent" => {
                "name" => "elk",
                "type" => "filebeat",
        "ephemeral_id" => "0b2f8e70-db95-437d-a46e-fc9b24b5846b",
                  "id" => "d7a4dfcb-de4e-4bbf-b0a1-060c65dab621",
             "version" => "8.18.1"
    },
         "event" => {
        "original" => "testing"
    },
          "host" => {
                  "mac" => [
            [0] "00-1C-42-6D-E0-89"
        ],
        "containerized" => false,
             "hostname" => "elk",
                   "os" => {
              "kernel" => "6.8.0-64-generic",
                "name" => "Ubuntu",
            "codename" => "noble",
                "type" => "linux",
            "platform" => "ubuntu",
              "family" => "debian",
             "version" => "24.04.2 LTS (Noble Numbat)"
        },
                 "name" => "elk",
                   "ip" => [
            [0] "10.211.55.32",
            [1] "fdb2:2c26:f4e4:0:21c:42ff:fe6d:e089",
            [2] "fe80::21c:42ff:fe6d:e089"
        ],
         "architecture" => "aarch64",
                   "id" => "53d351d845dc4ea09111e51cc53b4b62"
    },
          "tags" => [
        [0] "beats_input_codec_plain_applied"
    ],
           "ecs" => {
        "version" => "8.0.0"
    },
           "log" => {
        "offset" => 0,
          "file" => {
                "inode" => "131640",
                 "path" => "/var/log/my_data.log",
            "device_id" => "64512"
        }
    },
       "message" => "testing",
      "@version" => "1",
    "@timestamp" => 2025-08-03T03:08:45.890Z,
         "input" => {
        "type" => "filestream"
    }
}



### on Kibana 
next go to the kibana, go to stack management and you will see logs_for_test_<alias rolloever date>
next create the data view 
Dataview > index pattern
logs_for_test*


### parsening and FILTERING LOGS



### GROK
### next we will parse the logs to create more fields and apply the grok pattern in the message field and create more fields out of it. 



